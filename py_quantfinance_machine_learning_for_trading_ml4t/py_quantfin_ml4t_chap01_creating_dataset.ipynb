{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Algorithmic Trading Model with ML4T Creating Dataset Examples\n",
    "### David Lowe\n",
    "### July 1, 2022\n",
    "\n",
    "NOTE: This script is for learning purposes only and does not constitute a recommendation for buying or selling any stock mentioned in this script.\n",
    "\n",
    "SUMMARY: This project aims to construct and test an algorithmic trading model and document the end-to-end steps using a template.\n",
    "\n",
    "INTRODUCTION: This script aims to replicate the examples found in chapter one of the book Machine Learning for Algorithmic Trading by Stefan Jansen. The script seeks to validate further the Python environment and package requirements for running these code examples. The eventual goal is to integrate various example code segments into an end-to-end algorithmic trading system.\n",
    "\n",
    "This notebook contains information on downloading the stock information and several other sources used throughout the book.\n",
    "\n",
    "Dataset ML Model: Time series analysis with numerical attributes\n",
    "\n",
    "Dataset Used: Various data services from Nasdaq, Stooq, Wikipedia, etc.\n",
    "\n",
    "Source and Further Discussion of the Code Examples: https://www.ml4trading.io/chapter/1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Download and store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:32:07.092623Z",
     "start_time": "2020-06-18T14:32:07.090885Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:32:07.263130Z",
     "start_time": "2020-06-18T14:32:07.259861Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Set Data Store path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Modify path if you would like to store the data elsewhere and change the notebooks accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T02:27:54.832609Z",
     "start_time": "2020-06-19T02:27:54.824778Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_STORE = Path('assets.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Quandl Wiki Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Quandl has been [acuqired by NASDAQ](https://www.nasdaq.com/about/press-center/nasdaq-acquires-quandl-advance-use-alternative-data) in late 2018. In 2021, NASDAQ [integrated Quandl's data platform](https://data.nasdaq.com/). Free US equity data is still available under a [new URL](https://data.nasdaq.com/databases/WIKIP/documentation), subject to the limitations mentioned below.\n",
    "\n",
    "[NASDAQ](https://data.nasdaq.com/) makes available a [dataset](/home/stefan/drive/machine-learning-for-trading/data/create_datasets.ipynb) with stock prices, dividends and splits for 3000 US publicly-traded companies. Prior to its acquisition (April 11, 2018), Quandl announced the end of community support (updates). The historical data are useful as a first step towards demonstrating the application of the machine learning solutions, just ensure you design and test your own algorithms using current, professional-grade data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Follow the instructions to create a free [NASDAQ account](https://data.nasdaq.com/sign-up)\n",
    "2. [Download](https://data.nasdaq.com/tables/WIKIP/WIKI-PRICES/export) the entire WIKI/PRICES data\n",
    "3. Extract the .zip file,\n",
    "4. Move to this directory and rename to wiki_prices.csv\n",
    "5. Run the below code to store in fast HDF format (see [Chapter 02 on Market & Fundamental Data](../02_market_and_fundamental_data) for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:38:46.759327Z",
     "start_time": "2020-06-16T21:37:48.398856Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 15389314 entries, (Timestamp('1962-01-02 00:00:00'), 'ARNC') to (Timestamp('2018-03-27 00:00:00'), 'ZUMZ')\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count     Dtype  \n",
      "---  ------       --------------     -----  \n",
      " 0   open         15388776 non-null  float64\n",
      " 1   high         15389259 non-null  float64\n",
      " 2   low          15389259 non-null  float64\n",
      " 3   close        15389313 non-null  float64\n",
      " 4   volume       15389314 non-null  float64\n",
      " 5   ex-dividend  15389314 non-null  float64\n",
      " 6   split_ratio  15389313 non-null  float64\n",
      " 7   adj_open     15388776 non-null  float64\n",
      " 8   adj_high     15389259 non-null  float64\n",
      " 9   adj_low      15389259 non-null  float64\n",
      " 10  adj_close    15389313 non-null  float64\n",
      " 11  adj_volume   15389314 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 1.4+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv('wiki_prices.csv',\n",
    "                 parse_dates=['date'],\n",
    "                 index_col=['date', 'ticker'],\n",
    "                 infer_datetime_format=True)\n",
    "     .sort_index())\n",
    "\n",
    "print(df.info(null_counts=True))\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('quandl/wiki/prices', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Wiki Prices Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> QUANDL used to make some stock meta data be available on its website; I'm making the file available to allow readers to run some examples in the book:\n",
    "\n",
    "Instead of using the QUANDL API, load the file `wiki_stocks.csv` as described and store in HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3199 entries, 0 to 3198\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   code    3199 non-null   object\n",
      " 1   name    3199 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 50.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wiki_stocks.csv')\n",
    "# no longer needed\n",
    "# df = pd.concat([df.loc[:, 'code'].str.strip(),\n",
    "#                 df.loc[:, 'name'].str.split('(', expand=True)[0].str.strip().to_frame('name')], axis=1)\n",
    "\n",
    "print(df.info(null_counts=True))\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('quandl/wiki/stocks', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## S&P 500 Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following code downloads historical S&P 500 prices from FRED (only last 10 years of daily data is freely available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2608 entries, 2012-06-28 to 2022-06-27\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   close   2515 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 40.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = web.DataReader(name='SP500', data_source='fred', start=2009).squeeze().to_frame('close')\n",
    "print(df.info())\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('sp500/fred', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Alternatively, download S&P500 data from [stooq.com](https://stooq.com/q/?s=%5Espx&c=1d&t=l&a=lg&b=0); at the time of writing the data was available since 1789. You can switch from Polish to English on the lower right-hand side.\n",
    "\n",
    "We store the data from 1950-2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:42:08.524471Z",
     "start_time": "2020-06-16T21:42:08.415664Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17700 entries, 1950-01-03 to 2019-12-31\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   open    17700 non-null  float64\n",
      " 1   high    17700 non-null  float64\n",
      " 2   low     17700 non-null  float64\n",
      " 3   close   17700 non-null  float64\n",
      " 4   volume  17700 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 829.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sp500_stooq = (pd.read_csv('^spx_d.csv', index_col=0,\n",
    "                     parse_dates=True).loc['1950':'2019'].rename(columns=str.lower))\n",
    "print(sp500_stooq.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:42:09.567451Z",
     "start_time": "2020-06-16T21:42:09.556832Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('sp500/stooq', sp500_stooq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### S&P 500 Constituents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following code downloads the current S&P 500 constituents from [Wikipedia](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T10:50:19.998830Z",
     "start_time": "2020-06-17T10:50:18.784120Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "df = pd.read_html(url, header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T10:50:21.745331Z",
     "start_time": "2020-06-17T10:50:21.724637Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Symbol     Security SEC filings  GICS Sector         GICS Sub-Industry    Headquarters Location Date first added      CIK      Founded\n0    MMM           3M     reports  Industrials  Industrial Conglomerates    Saint Paul, Minnesota       1976-08-09    66740         1902\n1    AOS  A. O. Smith     reports  Industrials         Building Products     Milwaukee, Wisconsin       2017-07-26    91142         1916\n2    ABT       Abbott     reports  Health Care     Health Care Equipment  North Chicago, Illinois       1964-03-31     1800         1888\n3   ABBV       AbbVie     reports  Health Care           Pharmaceuticals  North Chicago, Illinois       2012-12-31  1551152  2013 (1888)\n4   ABMD      Abiomed     reports  Health Care     Health Care Equipment   Danvers, Massachusetts       2018-05-31   815094         1981",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbol</th>\n      <th>Security</th>\n      <th>SEC filings</th>\n      <th>GICS Sector</th>\n      <th>GICS Sub-Industry</th>\n      <th>Headquarters Location</th>\n      <th>Date first added</th>\n      <th>CIK</th>\n      <th>Founded</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MMM</td>\n      <td>3M</td>\n      <td>reports</td>\n      <td>Industrials</td>\n      <td>Industrial Conglomerates</td>\n      <td>Saint Paul, Minnesota</td>\n      <td>1976-08-09</td>\n      <td>66740</td>\n      <td>1902</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AOS</td>\n      <td>A. O. Smith</td>\n      <td>reports</td>\n      <td>Industrials</td>\n      <td>Building Products</td>\n      <td>Milwaukee, Wisconsin</td>\n      <td>2017-07-26</td>\n      <td>91142</td>\n      <td>1916</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ABT</td>\n      <td>Abbott</td>\n      <td>reports</td>\n      <td>Health Care</td>\n      <td>Health Care Equipment</td>\n      <td>North Chicago, Illinois</td>\n      <td>1964-03-31</td>\n      <td>1800</td>\n      <td>1888</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ABBV</td>\n      <td>AbbVie</td>\n      <td>reports</td>\n      <td>Health Care</td>\n      <td>Pharmaceuticals</td>\n      <td>North Chicago, Illinois</td>\n      <td>2012-12-31</td>\n      <td>1551152</td>\n      <td>2013 (1888)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ABMD</td>\n      <td>Abiomed</td>\n      <td>reports</td>\n      <td>Health Care</td>\n      <td>Health Care Equipment</td>\n      <td>Danvers, Massachusetts</td>\n      <td>2018-05-31</td>\n      <td>815094</td>\n      <td>1981</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T10:51:06.628859Z",
     "start_time": "2020-06-17T10:51:06.621125Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['ticker', 'name', 'sec_filings', 'gics_sector', 'gics_sub_industry',\n",
    "              'location', 'first_added', 'cik', 'founded']\n",
    "df = df.drop('sec_filings', axis=1).set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T10:51:14.523579Z",
     "start_time": "2020-06-17T10:51:14.515004Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 503 entries, MMM to ZTS\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   name               503 non-null    object\n",
      " 1   gics_sector        503 non-null    object\n",
      " 2   gics_sub_industry  503 non-null    object\n",
      " 3   location           503 non-null    object\n",
      " 4   first_added        458 non-null    object\n",
      " 5   cik                503 non-null    int64 \n",
      " 6   founded            503 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T10:51:17.814771Z",
     "start_time": "2020-06-17T10:51:17.788608Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('sp500/stocks', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metadata on US-traded companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following downloads several attributes for [companies](https://www.nasdaq.com/screening/companies-by-name.aspx) traded on NASDAQ, AMEX and NYSE\n",
    "\n",
    "> Update: unfortunately, NASDAQ has disabled automatic downloads. However, you can still access and manually download the files at the below URL when you fill in the exchange names. So for AMEX, URL becomes `https://www.nasdaq.com/market-activity/stocks/screener?exchange=AMEX&letter=0&render=download`.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8541 entries, AACG to ZYME\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   name        8541 non-null   object \n",
      " 1   last sale   8541 non-null   object \n",
      " 2   net change  8541 non-null   float64\n",
      " 3   % change    8540 non-null   object \n",
      " 4   market cap  8077 non-null   float64\n",
      " 5   country     7731 non-null   object \n",
      " 6   ipo year    5285 non-null   float64\n",
      " 7   volume      8541 non-null   int64  \n",
      " 8   sector      7065 non-null   object \n",
      " 9   industry    7064 non-null   object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 734.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# no longer works!\n",
    "# url = 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange={}&render=download'\n",
    "\n",
    "# but this should work after manually downloading tickers for three exchanges!\n",
    "url = 'nasdaq_screener_{}.csv'\n",
    "exchanges = ['NASDAQ', 'AMEX', 'NYSE']\n",
    "df = pd.concat([pd.read_csv(url.format(ex)) for ex in exchanges]).dropna(how='all', axis=1)\n",
    "# df = df.rename(columns=str.lower).set_index('symbol').drop('summary quote', axis=1)\n",
    "df = df.rename(columns=str.lower).set_index('symbol')\n",
    "df = df[~df.index.duplicated()]\n",
    "print(df.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    name last sale  net change % change   market cap        country  ipo year  volume                  sector                                    industry\nsymbol                                                                                                                                                                                                   \nAACG    ATA Creativity Global American Depositary Shares    $1.115       0.025   2.294%   35232426.0          China    2008.0    6739  Consumer Discretionary              Service to the Health Industry\nAACI             Armada Acquisition Corp. I Common Stock    $9.875      -0.005  -0.051%  204506313.0  United States    2021.0     203             Industrials             Consumer Electronics/Appliances\nAACIU                    Armada Acquisition Corp. I Unit     $9.93       0.000    0.00%          0.0  United States    2021.0       1             Industrials             Consumer Electronics/Appliances\nAACIW                 Armada Acquisition Corp. I Warrant     $0.18      -0.020  -10.00%          0.0  United States    2021.0   77400             Industrials             Consumer Electronics/Appliances\nAADI                   Aadi Bioscience Inc. Common Stock    $11.92      -0.180  -1.488%  249628318.0  United States       NaN  478394             Health Care  Biotechnology: Pharmaceutical Preparations",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>last sale</th>\n      <th>net change</th>\n      <th>% change</th>\n      <th>market cap</th>\n      <th>country</th>\n      <th>ipo year</th>\n      <th>volume</th>\n      <th>sector</th>\n      <th>industry</th>\n    </tr>\n    <tr>\n      <th>symbol</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AACG</th>\n      <td>ATA Creativity Global American Depositary Shares</td>\n      <td>$1.115</td>\n      <td>0.025</td>\n      <td>2.294%</td>\n      <td>35232426.0</td>\n      <td>China</td>\n      <td>2008.0</td>\n      <td>6739</td>\n      <td>Consumer Discretionary</td>\n      <td>Service to the Health Industry</td>\n    </tr>\n    <tr>\n      <th>AACI</th>\n      <td>Armada Acquisition Corp. I Common Stock</td>\n      <td>$9.875</td>\n      <td>-0.005</td>\n      <td>-0.051%</td>\n      <td>204506313.0</td>\n      <td>United States</td>\n      <td>2021.0</td>\n      <td>203</td>\n      <td>Industrials</td>\n      <td>Consumer Electronics/Appliances</td>\n    </tr>\n    <tr>\n      <th>AACIU</th>\n      <td>Armada Acquisition Corp. I Unit</td>\n      <td>$9.93</td>\n      <td>0.000</td>\n      <td>0.00%</td>\n      <td>0.0</td>\n      <td>United States</td>\n      <td>2021.0</td>\n      <td>1</td>\n      <td>Industrials</td>\n      <td>Consumer Electronics/Appliances</td>\n    </tr>\n    <tr>\n      <th>AACIW</th>\n      <td>Armada Acquisition Corp. I Warrant</td>\n      <td>$0.18</td>\n      <td>-0.020</td>\n      <td>-10.00%</td>\n      <td>0.0</td>\n      <td>United States</td>\n      <td>2021.0</td>\n      <td>77400</td>\n      <td>Industrials</td>\n      <td>Consumer Electronics/Appliances</td>\n    </tr>\n    <tr>\n      <th>AADI</th>\n      <td>Aadi Bioscience Inc. Common Stock</td>\n      <td>$11.92</td>\n      <td>-0.180</td>\n      <td>-1.488%</td>\n      <td>249628318.0</td>\n      <td>United States</td>\n      <td>NaN</td>\n      <td>478394</td>\n      <td>Health Care</td>\n      <td>Biotechnology: Pharmaceutical Preparations</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# tweak the columns so they match the examples in the book\n",
    "df.drop(columns=['net change','% change','country','volume'], inplace=True)\n",
    "df.rename(columns={\"last sale\": \"lastsale\",\n",
    "                   \"market cap\": \"marketcap\",\n",
    "                   \"ipo year\": \"ipoyear\"}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    name lastsale    marketcap  ipoyear                  sector                                    industry\nsymbol                                                                                                                                                     \nAACG    ATA Creativity Global American Depositary Shares   $1.115   35232426.0   2008.0  Consumer Discretionary              Service to the Health Industry\nAACI             Armada Acquisition Corp. I Common Stock   $9.875  204506313.0   2021.0             Industrials             Consumer Electronics/Appliances\nAACIU                    Armada Acquisition Corp. I Unit    $9.93          0.0   2021.0             Industrials             Consumer Electronics/Appliances\nAACIW                 Armada Acquisition Corp. I Warrant    $0.18          0.0   2021.0             Industrials             Consumer Electronics/Appliances\nAADI                   Aadi Bioscience Inc. Common Stock   $11.92  249628318.0      NaN             Health Care  Biotechnology: Pharmaceutical Preparations",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>lastsale</th>\n      <th>marketcap</th>\n      <th>ipoyear</th>\n      <th>sector</th>\n      <th>industry</th>\n    </tr>\n    <tr>\n      <th>symbol</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AACG</th>\n      <td>ATA Creativity Global American Depositary Shares</td>\n      <td>$1.115</td>\n      <td>35232426.0</td>\n      <td>2008.0</td>\n      <td>Consumer Discretionary</td>\n      <td>Service to the Health Industry</td>\n    </tr>\n    <tr>\n      <th>AACI</th>\n      <td>Armada Acquisition Corp. I Common Stock</td>\n      <td>$9.875</td>\n      <td>204506313.0</td>\n      <td>2021.0</td>\n      <td>Industrials</td>\n      <td>Consumer Electronics/Appliances</td>\n    </tr>\n    <tr>\n      <th>AACIU</th>\n      <td>Armada Acquisition Corp. I Unit</td>\n      <td>$9.93</td>\n      <td>0.0</td>\n      <td>2021.0</td>\n      <td>Industrials</td>\n      <td>Consumer Electronics/Appliances</td>\n    </tr>\n    <tr>\n      <th>AACIW</th>\n      <td>Armada Acquisition Corp. I Warrant</td>\n      <td>$0.18</td>\n      <td>0.0</td>\n      <td>2021.0</td>\n      <td>Industrials</td>\n      <td>Consumer Electronics/Appliances</td>\n    </tr>\n    <tr>\n      <th>AADI</th>\n      <td>Aadi Bioscience Inc. Common Stock</td>\n      <td>$11.92</td>\n      <td>249628318.0</td>\n      <td>NaN</td>\n      <td>Health Care</td>\n      <td>Biotechnology: Pharmaceutical Preparations</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convert market cap information to numerical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Market cap is provided as strings so we need to convert it to numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mcap = df[['marketcap']].dropna()\n",
    "# mcap['suffix'] = mcap.marketcap.str[-1]\n",
    "# mcap.suffix.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Keep only values with value units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mcap = mcap[mcap.suffix.str.endswith(('B', 'M'))]\n",
    "# mcap.marketcap = pd.to_numeric(mcap.marketcap.str[1:-1])\n",
    "# mcaps = {'M': 1e6, 'B': 1e9}\n",
    "# for symbol, factor in mcaps.items():\n",
    "#     mcap.loc[mcap.suffix == symbol, 'marketcap'] *= factor\n",
    "# mcap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count                8,077\nmean         6,620,072,788\nstd         50,009,231,400\nmin                      0\n10%                      0\n20%             13,695,020\n30%             66,499,572\n40%            162,531,288\n50%            295,327,017\n60%            519,259,122\n70%          1,107,806,543\n80%          2,755,133,268\n90%          8,984,408,503\nmax      2,382,844,009,600\nName: marketcap, dtype: object"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['marketcap'] = mcap.marketcap\n",
    "df.marketcap.describe(percentiles=np.arange(.1, 1, .1).round(1)).apply(lambda x: f'{int(x):,d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Store result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The file `us_equities_meta_data.csv` contains a version of the data used for many of the examples. Load using \n",
    "```\n",
    "df = pd.read_csv('us_equities_meta_data.csv')\n",
    "```\n",
    "and proceed to store in HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:35:00.910722Z",
     "start_time": "2020-06-16T21:35:00.862761Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6834 entries, 0 to 6833\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ticker     6834 non-null   object \n",
      " 1   name       6834 non-null   object \n",
      " 2   lastsale   6718 non-null   float64\n",
      " 3   marketcap  5766 non-null   float64\n",
      " 4   ipoyear    3038 non-null   float64\n",
      " 5   sector     5288 non-null   object \n",
      " 6   industry   5288 non-null   object \n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 373.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('us_equities_meta_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T21:35:22.388412Z",
     "start_time": "2020-06-16T21:35:22.356828Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('us_equities/stocks', df.set_index('ticker'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:19:11.720146Z",
     "start_time": "2020-06-18T17:18:53.948739Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:19:11.723222Z",
     "start_time": "2020-06-18T17:19:11.721079Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n",
      "**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n",
      "**Please cite**:  \n",
      "\n",
      "The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n",
      "\n",
      "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n",
      "\n",
      "With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n",
      "\n",
      "The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "print(mnist.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:19:21.823457Z",
     "start_time": "2020-06-18T17:19:21.815369Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:19:59.989715Z",
     "start_time": "2020-06-18T17:19:59.983320Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist_path = Path('mnist')\n",
    "if not mnist_path.exists():\n",
    "    mnist_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T17:20:25.489271Z",
     "start_time": "2020-06-18T17:20:25.418621Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.save(mnist_path / 'data', mnist.data.astype(np.uint8))\n",
    "np.save(mnist_path / 'labels', mnist.target.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fashion MNIST Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We will use the Fashion MNIST image data created by [Zalando Research](https://github.com/zalandoresearch/fashion-mnist) for some demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:42:51.598398Z",
     "start_time": "2020-06-18T14:42:38.233167Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist = fetch_openml(name='Fashion-MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:42:51.604464Z",
     "start_time": "2020-06-18T14:42:51.599373Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Han Xiao, Kashif Rasul, Roland Vollgraf  \n",
      "**Source**: [Zalando Research](https://github.com/zalandoresearch/fashion-mnist)  \n",
      "**Please cite**: Han Xiao and Kashif Rasul and Roland Vollgraf, Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, arXiv, cs.LG/1708.07747  \n",
      "\n",
      "Fashion-MNIST is a dataset of Zalando's article images, consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. \n",
      "\n",
      "Raw data available at: https://github.com/zalandoresearch/fashion-mnist\n",
      "\n",
      "### Target classes\n",
      "Each training and test example is assigned to one of the following labels:\n",
      "Label  Description  \n",
      "0  T-shirt/top  \n",
      "1  Trouser  \n",
      "2  Pullover  \n",
      "3  Dress  \n",
      "4  Coat  \n",
      "5  Sandal  \n",
      "6  Shirt  \n",
      "7  Sneaker  \n",
      "8  Bag  \n",
      "9  Ankle boot\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "print(fashion_mnist.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T15:14:10.969125Z",
     "start_time": "2020-06-18T15:14:10.960466Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_dict = {0: 'T-shirt/top',\n",
    "              1: 'Trouser',\n",
    "              2: 'Pullover',\n",
    "              3: 'Dress',\n",
    "              4: 'Coat',\n",
    "              5: 'Sandal',\n",
    "              6: 'Shirt',\n",
    "              7: 'Sneaker',\n",
    "              8: 'Bag',\n",
    "              9: 'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T15:14:11.293906Z",
     "start_time": "2020-06-18T15:14:11.290279Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fashion_path = Path('fashion_mnist')\n",
    "if not fashion_path.exists():\n",
    "    fashion_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T15:14:11.941092Z",
     "start_time": "2020-06-18T15:14:11.926416Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(label_dict).to_csv(fashion_path / 'label_dict.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T14:45:50.376114Z",
     "start_time": "2020-06-18T14:45:50.301028Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.save(fashion_path / 'data', fashion_mnist.data.astype(np.uint8))\n",
    "np.save(fashion_path / 'labels', fashion_mnist.target.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bond Price Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following code downloads several bond indexes from the Federal Reserve Economic Data service ([FRED](https://fred.stlouisfed.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "securities = {'BAMLCC0A0CMTRIV'   : 'US Corp Master TRI',\n",
    "              'BAMLHYH0A0HYM2TRIV': 'US High Yield TRI',\n",
    "              'BAMLEMCBPITRIV'    : 'Emerging Markets Corporate Plus TRI',\n",
    "              # 'GOLDAMGBD228NLBM'  : 'Gold (London, USD)',  # No longer available from FRED\n",
    "              'DGS10'             : '10-Year Treasury CMR',\n",
    "              }\n",
    "\n",
    "df = web.DataReader(name=list(securities.keys()), data_source='fred', start=2000)\n",
    "df = df.rename(columns=securities).dropna(how='all').resample('B').mean()\n",
    "\n",
    "with pd.HDFStore(DATA_STORE) as store:\n",
    "    store.put('fred/assets', df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}